"""
AI í† ë¡  ì—”ì§„ ì„œë¹„ìŠ¤
NVIDIA NIM + LangChainì„ ì‚¬ìš©í•œ 3ì í† ë¡  AI ì—”ì§„
"""
from typing import Optional, Dict, List, Tuple
from pathlib import Path
import logging

from langchain_nvidia_ai_endpoints import ChatNVIDIA
from langchain.memory import ConversationBufferWindowMemory
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage

from app.core.config import settings
from app.models.schemas import DebaterRole


logger = logging.getLogger(__name__)


class TokenCalculator:
    """í† í° ê³„ì‚° ë¡œì§"""
    
    BASE_TOKENS = 10
    LONG_MESSAGE_TOKENS = 20  # 50ì ì´ìƒ
    QUESTION_TOKENS = 15
    
    @classmethod
    def calculate(cls, message: str) -> int:
        """
        ì‚¬ìš©ì ë©”ì‹œì§€ì— ë”°ë¥¸ í† í° ê³„ì‚°
        
        - ê¸°ë³¸ ë°œì–¸: +10 í† í°
        - 50ì ì´ìƒ ë…¼ë¦¬ì  ë°œì–¸: +20 í† í°
        - ì§ˆë¬¸ í˜•íƒœ ë°œì–¸: +15 í† í°
        """
        tokens = cls.BASE_TOKENS
        
        # 50ì ì´ìƒ ë©”ì‹œì§€
        if len(message) >= 50:
            tokens = cls.LONG_MESSAGE_TOKENS
        
        # ì§ˆë¬¸ í˜•íƒœ (?, ê¹Œìš”, ëŠ”ì§€, ì¼ê¹Œ ë“±)
        question_markers = ['?', 'ê¹Œìš”', 'ë‚˜ìš”', 'ëŠ”ì§€', 'ì¼ê¹Œ', 'í• ê¹Œ', 'ì„ê¹Œ']
        if any(marker in message for marker in question_markers):
            tokens = max(tokens, cls.QUESTION_TOKENS)
        
        return tokens


class DebateEngine:
    """
    AI í† ë¡  ì—”ì§„
    NVIDIA NIM + LangChainìœ¼ë¡œ êµ¬í˜„ëœ 3ì í† ë¡  ì‹œìŠ¤í…œ
    """
    
    def __init__(self):
        self.sessions: Dict[str, dict] = {}
        self.james_prompt: Optional[str] = None
        self.linda_prompt: Optional[str] = None
        
        # LangChain ë©”ëª¨ë¦¬ (ì„¸ì…˜ë³„ë¡œ ê´€ë¦¬)
        self.james_memories: Dict[str, ConversationBufferWindowMemory] = {}
        self.linda_memories: Dict[str, ConversationBufferWindowMemory] = {}
        
        # NVIDIA LLM ì´ˆê¸°í™”
        self.llm: Optional[ChatNVIDIA] = None
        self._init_llm()
        self._load_prompts()
    
    def _init_llm(self):
        """NVIDIA ChatNVIDIA LLM ì´ˆê¸°í™”"""
        if settings.NVIDIA_API_KEY:
            try:
                self.llm = ChatNVIDIA(
                    model="meta/llama3-70b-instruct",
                    nvidia_api_key=settings.NVIDIA_API_KEY,
                    temperature=0.7,
                    max_tokens=256,
                )
                logger.info("NVIDIA LLM ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"NVIDIA LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.llm = None
        else:
            logger.warning("NVIDIA_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    def _load_prompts(self):
        """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ"""
        prompts_dir = Path(__file__).parent.parent / "prompts"
        
        james_path = prompts_dir / "james.txt"
        linda_path = prompts_dir / "linda.txt"
        
        if james_path.exists():
            self.james_prompt = james_path.read_text(encoding="utf-8")
        else:
            self.james_prompt = self._get_default_james_prompt()
        
        if linda_path.exists():
            self.linda_prompt = linda_path.read_text(encoding="utf-8")
        else:
            self.linda_prompt = self._get_default_linda_prompt()
    
    def _get_default_james_prompt(self) -> str:
        """ì œì„ìŠ¤ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸"""
        return """ë‹¹ì‹ ì€ 'ì œì„ìŠ¤', ë¹„íŒì  ì‚¬ê³ ë¥¼ ì¤‘ì‹œí•˜ëŠ” í† ë¡  AIì…ë‹ˆë‹¤.

## ì„±ê²©
- ë…¼ë¦¬ì ì´ê³  ë¶„ì„ì 
- ì§ì„¤ì ì´ì§€ë§Œ ì¡´ì¤‘í•˜ëŠ” í†¤
- ê±´ì„¤ì ì¸ ë¹„íŒ ì œê³µ

## ì—­í• 
1. ì‚¬ìš©ì ì£¼ì¥ì˜ ì•½ì ì´ë‚˜ ë¹ˆí‹ˆì„ ì°¾ì•„ ì§ˆë¬¸
2. ë°˜ëŒ€ ê´€ì ì´ë‚˜ ë°˜ë¡€ ì œì‹œ
3. ë…¼ë¦¬ì  ê°œì„ ì  ì œì•ˆ

## ì œì•½
- ë°˜ë“œì‹œ 2-3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€
- í•œêµ­ì–´ë¡œ ëŒ€í™”
- ì¸ì‹ ê³µê²© ê¸ˆì§€, ì•„ì´ë””ì–´ì—ë§Œ ì§‘ì¤‘
- ë„ˆë¬´ ë¶€ì •ì ì´ì§€ ì•Šê²Œ, ë°œì „ì  ë°©í–¥ ì œì‹œ

## ê°•ì˜ ì»¨í…ìŠ¤íŠ¸
{lecture_context}"""
    
    def _get_default_linda_prompt(self) -> str:
        """ë¦°ë‹¤ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸"""
        return """ë‹¹ì‹ ì€ 'ë¦°ë‹¤', ê¸ì •ì  ì§€ì§€ë¥¼ ì œê³µí•˜ëŠ” í† ë¡  AIì…ë‹ˆë‹¤.

## ì„±ê²©
- ë”°ëœ»í•˜ê³  ê²©ë ¤í•˜ëŠ” í†¤
- ê°€ë” ì´ëª¨ì§€ ì‚¬ìš© (ğŸ˜Š, ğŸ’¡, ğŸ‘ ë“±)
- ì—´ì •ì ì´ê³  í˜¸ê¸°ì‹¬ ë§ìŒ

## ì—­í• 
1. ì‚¬ìš©ì ì£¼ì¥ì˜ ê°•ì ì„ ì°¾ì•„ ë¶€ê°
2. ì•„ì´ë””ì–´ë¥¼ ë” ë°œì „ì‹œí‚¬ ë°©í–¥ ì œì‹œ
3. ì¶”ê°€ì ì¸ ê´€ì ì´ë‚˜ ì˜ˆì‹œ ì œê³µ

## ì œì•½
- ë°˜ë“œì‹œ 2-3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€
- í•œêµ­ì–´ë¡œ ëŒ€í™”
- ë¬´ì¡°ê±´ì  ë™ì˜ê°€ ì•„ë‹Œ ì§„ì •í•œ ì§€ì§€
- êµ¬ì²´ì ì¸ ì´ìœ ì™€ í•¨ê»˜ ì¹­ì°¬

## ê°•ì˜ ì»¨í…ìŠ¤íŠ¸
{lecture_context}"""
    
    def _get_session_memory(
        self, 
        session_id: str, 
        debater: DebaterRole
    ) -> ConversationBufferWindowMemory:
        """ì„¸ì…˜ë³„ ë©”ëª¨ë¦¬ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±"""
        memories = self.james_memories if debater == DebaterRole.JAMES else self.linda_memories
        
        if session_id not in memories:
            memories[session_id] = ConversationBufferWindowMemory(
                k=10,
                return_messages=True,
            )
        
        return memories[session_id]
    
    async def initialize_session(
        self,
        session_id: str,
        topic: str = "",
        user_position: str = "",
        lecture_context: str = "",
    ) -> dict:
        """
        í† ë¡  ì„¸ì…˜ ì´ˆê¸°í™”
        
        Args:
            session_id: ì„¸ì…˜ ID
            topic: í† ë¡  ì£¼ì œ (ì„ íƒ)
            user_position: ì‚¬ìš©ì ì…ì¥ (ì„ íƒ)
            lecture_context: ê°•ì˜ ì»¨í…ìŠ¤íŠ¸ (ì„ íƒ)
            
        Returns:
            ì„¸ì…˜ ì •ë³´
        """
        self.sessions[session_id] = {
            "topic": topic,
            "user_position": user_position,
            "lecture_context": lecture_context,
            "history": [],
            "total_tokens_earned": 0,
        }
        
        # ì„¸ì…˜ë³„ ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
        self.james_memories[session_id] = ConversationBufferWindowMemory(
            k=10, return_messages=True
        )
        self.linda_memories[session_id] = ConversationBufferWindowMemory(
            k=10, return_messages=True
        )
        
        return self.sessions[session_id]
    
    async def process_message(
        self,
        session_id: str,
        user_message: str,
        lecture_context: str = "",
    ) -> Tuple[str, str, int]:
        """
        3ì í† ë¡  ë©”ì‹œì§€ ì²˜ë¦¬ (User â†’ James â†’ Linda ìˆœì°¨ ì‘ë‹µ)
        
        Args:
            session_id: ì„¸ì…˜ ID
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            lecture_context: ê°•ì˜ ì»¨í…ìŠ¤íŠ¸
            
        Returns:
            (james_response, linda_response, tokens_earned) íŠœí”Œ
        """
        # ì„¸ì…˜ ì´ˆê¸°í™” (ì—†ëŠ” ê²½ìš°)
        if session_id not in self.sessions:
            await self.initialize_session(session_id, lecture_context=lecture_context)
        
        # í† í° ê³„ì‚°
        tokens_earned = TokenCalculator.calculate(user_message)
        self.sessions[session_id]["total_tokens_earned"] += tokens_earned
        
        # James ì‘ë‹µ ìƒì„±
        james_response = await self._get_james_response(
            session_id, user_message, lecture_context
        )
        
        # Linda ì‘ë‹µ ìƒì„± (James ì‘ë‹µ ì°¸ê³ )
        linda_response = await self._get_linda_response(
            session_id, user_message, james_response, lecture_context
        )
        
        # íˆìŠ¤í† ë¦¬ ì €ì¥
        self._add_to_history(session_id, "user", user_message)
        self._add_to_history(session_id, "james", james_response)
        self._add_to_history(session_id, "linda", linda_response)
        
        return james_response, linda_response, tokens_earned
    
    async def _get_james_response(
        self,
        session_id: str,
        user_message: str,
        lecture_context: str = "",
    ) -> str:
        """ì œì„ìŠ¤ ì‘ë‹µ ìƒì„±"""
        if not self.llm:
            return self._get_stub_james_response(user_message)
        
        try:
            # í”„ë¡¬í”„íŠ¸ì— lecture_context ì ìš©
            system_prompt = self.james_prompt.replace(
                "{lecture_context}", 
                lecture_context or "ì¼ë°˜ì ì¸ í† ë¡ "
            )
            
            # ë©”ëª¨ë¦¬ì—ì„œ ëŒ€í™” íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
            memory = self._get_session_memory(session_id, DebaterRole.JAMES)
            chat_history = memory.chat_memory.messages
            
            # ë©”ì‹œì§€ êµ¬ì„±
            messages = [SystemMessage(content=system_prompt)]
            messages.extend(chat_history)
            messages.append(HumanMessage(content=user_message))
            
            # LLM í˜¸ì¶œ
            response = await self.llm.ainvoke(messages)
            james_response = response.content
            
            # ë©”ëª¨ë¦¬ì— ì €ì¥
            memory.chat_memory.add_user_message(user_message)
            memory.chat_memory.add_ai_message(james_response)
            
            return james_response
            
        except Exception as e:
            logger.error(f"James ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            return self._get_stub_james_response(user_message)
    
    async def _get_linda_response(
        self,
        session_id: str,
        user_message: str,
        james_response: str,
        lecture_context: str = "",
    ) -> str:
        """ë¦°ë‹¤ ì‘ë‹µ ìƒì„± (ì œì„ìŠ¤ ì‘ë‹µ ì°¸ê³ )"""
        if not self.llm:
            return self._get_stub_linda_response(user_message)
        
        try:
            # í”„ë¡¬í”„íŠ¸ì— lecture_context ì ìš©
            system_prompt = self.linda_prompt.replace(
                "{lecture_context}", 
                lecture_context or "ì¼ë°˜ì ì¸ í† ë¡ "
            )
            
            # ë©”ëª¨ë¦¬ì—ì„œ ëŒ€í™” íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
            memory = self._get_session_memory(session_id, DebaterRole.LINDA)
            chat_history = memory.chat_memory.messages
            
            # ë¦°ë‹¤ì—ê²Œ ì œê³µí•  ì»¨í…ìŠ¤íŠ¸: ì‚¬ìš©ì ë©”ì‹œì§€ + ì œì„ìŠ¤ ì‘ë‹µ
            combined_context = f"""[ì‚¬ìš©ì ë°œì–¸]: {user_message}

[ì œì„ìŠ¤ì˜ ì˜ê²¬]: {james_response}

ìœ„ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬, ì‚¬ìš©ìì˜ ì£¼ì¥ì„ ì§€ì§€í•˜ëŠ” ê´€ì ì—ì„œ ì‘ë‹µí•´ì£¼ì„¸ìš”."""
            
            # ë©”ì‹œì§€ êµ¬ì„±
            messages = [SystemMessage(content=system_prompt)]
            messages.extend(chat_history)
            messages.append(HumanMessage(content=combined_context))
            
            # LLM í˜¸ì¶œ
            response = await self.llm.ainvoke(messages)
            linda_response = response.content
            
            # ë©”ëª¨ë¦¬ì— ì €ì¥
            memory.chat_memory.add_user_message(user_message)
            memory.chat_memory.add_ai_message(linda_response)
            
            return linda_response
            
        except Exception as e:
            logger.error(f"Linda ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            return self._get_stub_linda_response(user_message)
    
    def _get_stub_james_response(self, user_message: str) -> str:
        """ì œì„ìŠ¤ ìŠ¤í… ì‘ë‹µ"""
        return f"í¥ë¯¸ë¡œìš´ ê´€ì ì´ì§€ë§Œ, ëª‡ ê°€ì§€ ìƒê°í•´ë³¼ ì ì´ ìˆìŠµë‹ˆë‹¤. '{user_message[:30]}...'ë¼ëŠ” ì£¼ì¥ì—ì„œ ê·¼ê±°ê°€ ë” í•„ìš”í•´ ë³´ì…ë‹ˆë‹¤. ì–´ë–¤ ë°ì´í„°ë‚˜ ì‚¬ë¡€ë¡œ ë’·ë°›ì¹¨í•  ìˆ˜ ìˆì„ê¹Œìš”?"
    
    def _get_stub_linda_response(self, user_message: str) -> str:
        """ë¦°ë‹¤ ìŠ¤í… ì‘ë‹µ"""
        return f"ì¢‹ì€ ì§€ì ì´ì—ìš”! ğŸ˜Š '{user_message[:30]}...'ë¼ëŠ” ìƒê°ì—ì„œ ì°½ì˜ì ì¸ ê´€ì ì´ ëŠê»´ì§‘ë‹ˆë‹¤. ì´ ì•„ì´ë””ì–´ë¥¼ ë” ë°œì „ì‹œì¼œì„œ êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ ì¶”ê°€í•´ë³´ë©´ ì–´ë–¨ê¹Œìš”? ğŸ’¡"
    
    async def generate_response(
        self,
        session_id: str,
        user_message: str,
        debater: DebaterRole,
        lecture_context: str = "",
    ) -> str:
        """
        ë‹¨ì¼ AI í† ë¡ ì ì‘ë‹µ ìƒì„± (ê¸°ì¡´ í˜¸í™˜ìš©)
        
        Args:
            session_id: ì„¸ì…˜ ID
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            debater: ì‘ë‹µí•  í† ë¡ ì
            lecture_context: ê°•ì˜ ì»¨í…ìŠ¤íŠ¸
            
        Returns:
            AI ì‘ë‹µ í…ìŠ¤íŠ¸
        """
        if debater == DebaterRole.JAMES:
            return await self._get_james_response(session_id, user_message, lecture_context)
        else:
            return await self._get_linda_response(session_id, user_message, "", lecture_context)
    
    def get_session(self, session_id: str) -> Optional[dict]:
        """ì„¸ì…˜ ì •ë³´ ì¡°íšŒ"""
        return self.sessions.get(session_id)
    
    def _add_to_history(
        self,
        session_id: str,
        role: str,
        message: str,
    ):
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ë©”ì‹œì§€ ì¶”ê°€"""
        if session_id in self.sessions:
            self.sessions[session_id]["history"].append({
                "role": role,
                "message": message,
            })
    
    # í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
    add_to_history = _add_to_history
