"""
FastAPI ë°±ì—”ë“œ - í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë³´ë‚¸ ì‚¬ìš©ì ì •ë³´ë¥¼ ë°›ì•„ì„œ AIì—ê²Œ ì „ë‹¬

ğŸ›‚ ìš”ì²­ íë¦„:
í”„ë¡ íŠ¸ì—”ë“œ (useChat) 
  â†’ ì‚¬ìš©ì ì •ë³´ í¬í•¨í•œ ChatRequest ì „ì†¡
  â†’ Backend (ì´ íŒŒì¼)
    â†’ AIì—ê²Œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¡œ ì‚¬ìš©ì ì •ë³´ ì „ë‹¬
    â†’ AIê°€ ì‘ë‹µ ìƒì„±
  â†’ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì‘ë‹µ í‘œì‹œ
"""

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional
from datetime import datetime
from enum import Enum
import os
from dotenv import load_dotenv

load_dotenv()

app = FastAPI(title="Yeoul AI Backend", version="1.0.0")

# ===== CORS ì„¤ì • =====
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",  # ë¡œì»¬ ê°œë°œ
        "http://localhost:3001",  # ë°±ì—”ë“œ ê°œë°œ
        "https://*.vercel.app",   # Vercel ë°°í¬
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ===== íƒ€ì… ì •ì˜ =====

class LectureLevel(str, Enum):
    beginner = "beginner"
    intermediate = "intermediate"
    advanced = "advanced"


class UserProfile(BaseModel):
    """ğŸ›‚ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë°›ì„ ì‚¬ìš©ì ì •ë³´"""
    id: str
    nickname: str
    email: Optional[str] = None
    interest: str  # e.g., "React", "Machine Learning"
    level: Optional[LectureLevel] = "beginner"
    createdAt: Optional[datetime] = None
    updatedAt: Optional[datetime] = None


class ChatRequest(BaseModel):
    """ğŸ’¬ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì „ì†¡í•˜ëŠ” ì±„íŒ… ìš”ì²­ (ì‚¬ìš©ì ì •ë³´ í¬í•¨!)"""
    user_input: str                    # "Custom Hooks ì •ë§ í•„ìš”í•´?"
    context: str                       # "React"
    user_profile: UserProfile          # ğŸ‘ˆ ì—¬ê¸°! ì‚¬ìš©ì ì •ë³´ê°€ í•¨ê»˜ ì˜µë‹ˆë‹¤
    lecture_id: Optional[int] = None


class ChatResponse(BaseModel):
    """âœ… ë°±ì—”ë“œì—ì„œ ë°˜í™˜í•˜ëŠ” ì‘ë‹µ"""
    message: str                       # AIì˜ ë‹µë³€
    sender: str                        # "james" ë˜ëŠ” "linda"
    tokens_earned: Optional[int] = 5   # í† í° ë³´ìƒ
    reasoning: Optional[str] = None    # AIì˜ ì¶”ë¡  ê³¼ì •


class DebateSessionRequest(BaseModel):
    """ğŸ¬ í† ë¡  ì„¸ì…˜ ì‹œì‘ ìš”ì²­"""
    user_profile: UserProfile
    topic: str
    lecture_id: int
    opponent: Optional[str] = "both"


# ===== í•¸ë“¤ëŸ¬ í•¨ìˆ˜ =====

def build_system_prompt(user_profile: UserProfile) -> str:
    """
    ğŸ§  AI ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    
    ì‚¬ìš©ì ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ AIì˜ ì„±ê²©ê³¼ ì§€ì‹œì‚¬í•­ì„ ì •ì˜í•©ë‹ˆë‹¤.
    """
    return f"""
ë‹¹ì‹ ì€ ì—¬ìš¸(Yeoul) êµìœ¡ í”Œë«í¼ì˜ AI í† ë¡  íŒŒíŠ¸ë„ˆì…ë‹ˆë‹¤.

[ì‚¬ìš©ì ì •ë³´]
- ì´ë¦„: {user_profile.nickname}
- ê´€ì‹¬ì‚¬: {user_profile.interest}
- ìˆ˜ì¤€: {user_profile.level}

[ì§€ì‹œì‚¬í•­]
1. ì‚¬ìš©ìì˜ ì´ë¦„ì„ í•œ ë²ˆ ì •ë„ ë¶€ë¥´ë©´ì„œ ì¹œê·¼í•˜ê²Œ ëŒ€í™”í•˜ì„¸ìš”.
2. ì‚¬ìš©ìì˜ ê´€ì‹¬ì‚¬({user_profile.interest})ì™€ ì—°ê´€ì§€ì–´ ì„¤ëª…í•˜ì„¸ìš”.
3. ì‚¬ìš©ìì˜ ìˆ˜ì¤€({user_profile.level})ì— ë§ê²Œ ê¹Šì´ë¥¼ ì¡°ì ˆí•˜ì„¸ìš”.
4. ë…¼ë¦¬ì ì´ê³  ê±´ì„¤ì ì¸ í† ë¡ ì„ ì§„í–‰í•˜ì„¸ìš”.
5. ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ì‘ë‹µì„ ì œê³µí•˜ì„¸ìš”.
"""


async def call_ai_with_user_context(
    user_input: str,
    user_profile: UserProfile,
    context: str,
    ai_persona: str  # "james" ë˜ëŠ” "linda"
) -> str:
    """
    ğŸ¤– ì‹¤ì œ AI í˜¸ì¶œ (LangChain, Claude API ë“±)
    
    TODO: ì‹¤ì œ êµ¬í˜„ ì‹œ ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
    1. LangChain ë˜ëŠ” ì§ì ‘ APIë¡œ Claude/Llama í˜¸ì¶œ
    2. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©ì ì •ë³´ í¬í•¨
    3. AI í˜ë¥´ì†Œë‚˜(James/Linda) ì„ íƒ
    """
    
    system_prompt = build_system_prompt(user_profile)
    
    # ì˜ˆì‹œ ì‘ë‹µ (ì‹¤ì œë¡œëŠ” AIê°€ ìƒì„±)
    ai_responses = {
        "james": f"{user_profile.nickname}ë‹˜, í¥ë¯¸ë¡œìš´ ê´€ì ì´ë„¤ìš”. í•˜ì§€ë§Œ {user_profile.interest}ì—ì„œëŠ” ì–´ë–»ê²Œ ì ìš©ë ê¹Œìš”?",
        "linda": f"{user_profile.nickname}ë‹˜ì˜ ì ‘ê·¼ë²• ì •ë§ ì¢‹ìŠµë‹ˆë‹¤! {user_profile.interest} ë¶„ì•¼ì—ì„œë„ ì´ë ‡ê²Œ í™œìš©í•  ìˆ˜ ìˆì–´ìš”.",
    }
    
    return ai_responses.get(ai_persona, "ì¢‹ì€ ì§ˆë¬¸ì…ë‹ˆë‹¤!")


# ===== API ì—”ë“œí¬ì¸íŠ¸ =====

@app.get("/api/v1/health")
async def health_check():
    """â¤ï¸ í—¬ìŠ¤ ì²´í¬"""
    return {"status": "ok", "service": "Yeoul AI Backend"}


@app.post("/api/v1/debate/message", response_model=ChatResponse)
async def debate_message(request: ChatRequest) -> ChatResponse:
    """
    ğŸ’¬ í† ë¡  ë©”ì‹œì§€ ì²˜ë¦¬ (ì‚¬ìš©ì ì •ë³´ í™œìš©!)
    
    ìš”ì²­:
    {
        "user_input": "Custom Hooksê°€ ì •ë§ í•„ìš”í• ê¹Œìš”?",
        "context": "React",
        "user_profile": {
            "id": "user_123",
            "nickname": "ì§€ë¯¼",
            "interest": "React",
            "level": "intermediate"
        }
    }
    
    ì‘ë‹µ:
    {
        "message": "ì§€ë¯¼ë‹˜, ì¢‹ì€ ì§ˆë¬¸ì…ë‹ˆë‹¤...",
        "sender": "james",
        "tokens_earned": 5
    }
    """
    
    # ğŸ›‚ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë°›ì€ ì‚¬ìš©ì ì •ë³´ ì‚¬ìš©
    user_name = request.user_profile.nickname
    user_interest = request.user_profile.interest
    user_level = request.user_profile.level
    
    # ğŸ¤– AI í˜ë¥´ì†Œë‚˜ ì„ íƒ (ë²ˆê°ˆì•„ê°€ë©°)
    import random
    persona = random.choice(["james", "linda"])
    
    # ğŸ§  AIì—ê²Œ ì‚¬ìš©ì ì •ë³´ì™€ í•¨ê»˜ ì§ˆë¬¸
    ai_response = await call_ai_with_user_context(
        user_input=request.user_input,
        user_profile=request.user_profile,
        context=request.context,
        ai_persona=persona
    )
    
    # âœ… ì‘ë‹µ ë°˜í™˜
    return ChatResponse(
        message=ai_response,
        sender=persona,
        tokens_earned=5,
        reasoning=f"User '{user_name}' asked about {request.context}"
    )


@app.post("/api/v1/debate/start")
async def start_debate(request: DebateSessionRequest):
    """ğŸ¬ í† ë¡  ì„¸ì…˜ ì‹œì‘"""
    
    user_name = request.user_profile.nickname
    
    return {
        "session_id": f"session_{request.user_profile.id}_{int(datetime.now().timestamp())}",
        "topic": request.topic,
        "started_at": datetime.now().isoformat(),
        "james_response": f"{user_name}ë‹˜, {request.topic}ì— ëŒ€í•´ í† ë¡ í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.",
        "linda_response": f"ì¢‹ì•„ìš”, {user_name}ë‹˜! í•¨ê»˜ ê¹Šì´ ìˆê²Œ ì‚´í´ë´…ì‹œë‹¤."
    }


@app.post("/api/v1/voice/synthesize")
async def synthesize_voice(request: dict):
    """
    ğŸ™ï¸ TTS (Text-to-Speech)
    
    TODO: ElevenLabs API ì—°ë™
    """
    text = request.get("text")
    voice = request.get("voice")  # "james" ë˜ëŠ” "linda"
    
    return {
        "status": "success",
        "audio_url": f"https://elevenlabs.example.com/audio/{voice}.mp3"
    }


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
